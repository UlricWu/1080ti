{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxopt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "d = 5\n",
    "x = np.random.normal(size=(n,d))\n",
    "error = np.random.normal(size=(n,1))\n",
    "\n",
    "b = np.random.uniform(size=(d,1))\n",
    "\n",
    "### in order to avoid Perfect Separation, we need to add some noise\n",
    "y = x@b + error\n",
    "\n",
    "# y = list(map(lambda x: 1 if x > 0 else 0, y))\n",
    "# y = np.array(y)\n",
    "\n",
    "# binary\n",
    "y = np.array([0 if x <0 else 1  for x in y]).reshape(-1,1)\n",
    "# y = np.where(y<0, 0, 1)\n",
    "## 3 classes\n",
    "# y = np.array([0 if x < -1 else 1 if x < 1 else 2 for x in y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generate_process:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y    \n",
    "        \n",
    "    def split(self, rate = 0.7, random_state = 1024, scale = False):\n",
    "        ## Feature scaling is used to normalize the range of independent variables or features of data\n",
    "        if scale:\n",
    "            self.x = (self.x - np.mean(self.x))/x.std()\n",
    "        \n",
    "        n = len(self.y)\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "        ##randomly spilte data into 70% train and 30% test\n",
    "        index = list(range(n))\n",
    "        np.random.shuffle(index)\n",
    "        train = index[:int(rate*n)]\n",
    "        test = index[int(rate*n):]\n",
    "        \n",
    "        self.x_train = self.x[train]\n",
    "        self.x_test = self.x[test]\n",
    "        self.y_train = self.y[train]\n",
    "        self.y_test = self.y[test]\n",
    "        \n",
    "        return self.x_train, self.x_test, self.y_train, self.y_test\n",
    "    \n",
    "x_train, x_test, y_train, y_test = data_generate_process(x, y).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n",
    "## https://en.wikipedia.org/wiki/Support-vector_machine\n",
    "\n",
    "## $min D(\\beta) = 1/2 \\beta' \\beta $\n",
    "##    $  s.t. \\forall_i    y_i(x\\dot \\beta) \\geqslant 1 $\n",
    "# ====>1. Lagrangian duality\n",
    "## $max D(\\alpha) = \\sum \\alpha_i - 1/2 \\sum y_i \\alpha_i y_j\\alpha_j \\Phi(x_i, x_j)$\n",
    "## $ s.t. \\forall_i  \\alpha_i > 0$ and $ \\sum_i y_i \\alpha_i = 0$\n",
    "# =====> or 2. GradientDescend\n",
    "## cost function $f(\\beta) = 1/2 \\alpha \\beta ' \\beta +  average (\\sum_i max(0, 1 -y_i(X \\beta)))$\n",
    "# => Stochastic sub-Gradicent Descent\n",
    "##  CostFunction $f(\\beta) = 1/2 \\lambda \\beta ' \\beta + average( C \\sum_i max(0, 1 -y_i(X \\beta)))$\n",
    "##       $ \\beta_(t+1) = \\beta_t - \\alpha_t (\\lambda \\beta_t - y_i x_i) $      if $ y_i \\beta x_i <= 1 $\n",
    "##            $ \\beta_(t+1)= \\beta_t - \\alpha_t \\lambda \\beta_t  $ else\n",
    "## LearningRate $\\alpha = 1/(1 + epoch) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model:\n",
    "    def __init__(self, x, y,  bias = True):\n",
    "        \n",
    "        if bias:\n",
    "            x = self.getBias(x)\n",
    "            \n",
    "        self.x = x\n",
    "        self.y = [1 if item > 0 else -1 for item in y]\n",
    "    \n",
    "    def getBias(self, x):\n",
    "        ones = np.ones((len(x),1))\n",
    "        return np.hstack((ones,x))\n",
    "    \n",
    "    def fit(self, kernel = None, parameter = 1, iteration = 500, C = 0.02, threshold = 1e-3):\n",
    "        self.kernel = kernel\n",
    "        self.parameter = parameter\n",
    "        \n",
    "        x = self.getKernel(self.x, self.x, kernel = self.kernel)\n",
    "        y = self.y\n",
    "        \n",
    "        beta = np.zeros((x.shape[1], 1))\n",
    "        \n",
    "        for epoch in range(iteration):\n",
    "            learning = 1/(1+epoch)\n",
    "            \n",
    "            for i in range(len(x)):\n",
    "                if y[i]*x[i]@beta  < 1:\n",
    "                    update = learning *(C*beta - (y[i]*x[i]).reshape(-1,1))\n",
    "                else:\n",
    "                    update = learning*(C*beta)\n",
    "                \n",
    "                beta -= update\n",
    "                ## stop when enough close to the global minimal\n",
    "                if (epoch > 1) and np.abs(update).sum()< threshold:\n",
    "                    self.beta = beta\n",
    "                    return self.beta\n",
    "                \n",
    "        self.beta = beta\n",
    "        return self.beta \n",
    "    \n",
    "    def getKernel(self, x, z, kernel = None):\n",
    "        if self.kernel is None:\n",
    "            return x\n",
    "        \n",
    "        if self.kernel == 'linear':\n",
    "            return x@(z.T)\n",
    "        \n",
    "        if self.kernel == 'polynominal':\n",
    "            return np.power(1 + x@z.T, self.parameter)\n",
    "        \n",
    "        if self.kernel == 'rbf':\n",
    "            ## use euclidean_dist_matrix K(x, y) = e^(-g||x - z||^2)\n",
    "            norms_1 = (x ** 2).sum(axis=1)\n",
    "            norms_2 = (z ** 2).sum(axis=1)\n",
    "            distance = np.abs(norms_1.reshape(-1, 1) + norms_2 - 2 * np.dot(x, z.T))\n",
    "            return np.exp(-self.parameter* distance)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        x = self.getBias(x)\n",
    "        newx = self.getKernel(x, self.x)\n",
    "        return (newx@self.beta> 0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[117,  40],\n",
       "       [ 28, 115]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "svm = model(x_train, y_train)\n",
    "svm.fit()\n",
    "pred = svm.predict(x_test)\n",
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112,  45],\n",
       "       [ 39, 104]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = model(x_train, y_train)\n",
    "svm.fit(kernel = 'linear')\n",
    "pred =svm.predict(x_test)\n",
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119,  38],\n",
       "       [ 32, 111]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = model(x_train, y_train)\n",
    "svm.fit(kernel = 'rbf', parameter = 0.5)\n",
    "pred =svm.predict(x_test)\n",
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[107,  50],\n",
       "       [ 31, 112]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = model(x_train, y_train)\n",
    "svm.fit(kernel='polynominal', parameter = 3)\n",
    "pred =svm.predict(x_test)\n",
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compared to sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[121,  36],\n",
       "       [ 34, 109]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "start = time.time()\n",
    "linear_svc = svm.SVC(kernel='linear', gamma = 0.5)\n",
    "linear_svc.fit(x_train, y_train.ravel())\n",
    "y_pred = linear_svc.predict(x_test)\n",
    "end = time.time()\n",
    "sk_svm = end - start\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[117,  40],\n",
       "       [ 37, 106]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svc = svm.SVC(kernel='rbf', gamma = 0.5)\n",
    "linear_svc.fit(x_train, y_train.ravel())\n",
    "y_pred = linear_svc.predict(x_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[111,  46],\n",
       "       [ 34, 109]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svc = svm.SVC(kernel='poly', gamma = 0.5)\n",
    "linear_svc.fit(x_train, y_train.ravel())\n",
    "y_pred = linear_svc.predict(x_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
