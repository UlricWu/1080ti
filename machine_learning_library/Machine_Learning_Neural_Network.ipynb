{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 2,
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
<<<<<<< HEAD
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "import time\n",
    "# import cvxopt"
=======
    "import cvxopt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score"
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.power(10,6)\n",
    "d = 10\n",
    "x = np.random.normal(size=(n,d))\n",
    "error = np.random.normal(size=(n,1))\n",
    "b = np.random.uniform(size=(d,1))\n",
    "\n",
    "### in order to avoid Perfect Separation, we need to add some noise\n",
    "y = x@b + error"
=======
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CPZ_data_mini.csv')\n",
    "\n",
    "df.sort_values(by=['permno','Date'], inplace= True)\n",
    "df['ret_future'] = df.groupby('permno')['ret'].shift(-1)"
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generate_process:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y    \n",
    "        \n",
    "    def split(self, rate = 0.7, random_state = 1024, scale = False):\n",
    "        ## Feature scaling is used to normalize the range of independent variables or features of data\n",
    "        if scale:\n",
    "            self.x = (self.x - np.mean(self.x))/x.std()\n",
    "        \n",
    "        n = len(self.y)\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "        ##randomly spilte data into 70% train and 30% test\n",
    "        index = list(range(n))\n",
    "        np.random.shuffle(index)\n",
    "        train = index[:int(rate*n)]\n",
    "        test = index[int(rate*n):]\n",
    "        \n",
    "        self.train_x = self.x[train]\n",
    "        self.test_x = self.x[test]\n",
    "        self.train_y = self.y[train]\n",
    "        self.test_y = self.y[test]\n",
    "        \n",
    "        return self.train_x, self.test_x, self.train_y, self.test_y\n",
    "    \n",
    "train_x, test_x, train_y, test_y = data_generate_process(x, y).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  $ cost = 1/(pred - true)^2 \\; $  for Regression\n",
    "## $ \\theta_L$ = pred - true \n",
    "## $ \\theta_i = (theta_(i+1)). \\dot Weight_i * Activation'(alpha_i) $\n",
    "##    $ update_i = (\\alpha_i.T) . \\dot (\\theta_(i+1)) $\n",
    "##  $ weight_i.shape = (\\alpha_i.shape[1]+1, \\alpha_i.shape[1]+1) $\n",
    "##  $ weight_L.shape = (\\alpha_(L-1).shape[1]+1, 1 \\; or  \\;labels) $\n",
    "\n"
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['ret']\n",
    "x = df.drop(columns = ['Date', 'permno', 'ret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x -= x.mean()\n",
    "x /= x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as sk\n",
    "\n",
    "x_train, x_test, y_train, y_test = sk.train_test_split(x, y,test_size=0.3, random_state = 42)\n",
    "\n",
    "x_train, x_val, y_train, y_val = sk.train_test_split(x_train, y_train, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((597091, 19), (255897, 19), (365567, 19))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import he_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-424-0283124c18cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;32min\u001b[0m \u001b[0malpha_range\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0merror_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_nn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-424-0283124c18cd>\u001b[0m in \u001b[0;36mtrain_nn\u001b[1;34m(X, y, X_vali, y_vali, alpha, epochs, num_layers, num_neurons, lamda, p)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_nn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_vali\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_vali\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_neurons\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlamda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     model.add(Dense(num_neurons[0], activation='relu',\n\u001b[0;32m      4\u001b[0m                         \u001b[0mkernel_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlamda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                         \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhe_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "def train_nn(X, y, X_vali, y_vali, alpha, epochs=20, num_layers = 3, num_neurons = [16,8,1], lamda=0.0001,p=0.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_neurons[0], activation='relu',\n",
    "                        kernel_regularizer=l2(lamda), \n",
    "                        kernel_initializer=he_normal(),\n",
    "                        input_dim=X.shape[1]))\n",
    "    model.add(Dropout(p))\n",
    "\n",
    "    for i in range(1, num_layers-1):\n",
    "        model.add(Dense(num_neurons[i], activation='relu', \n",
    "                        kernel_regularizer=l2(lamda), \n",
    "                        kernel_initializer=he_normal()))\n",
    "        model.add(Dropout(p))\n",
    "\n",
    "    model.add(Dense(1, activation='linear',\n",
    "                    kernel_initializer=he_normal()))\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                      optimizer=Adam(learning_rate=alpha),\n",
    "                      metrics=['mse'])\n",
    "    \n",
    "    return model.fit(X, y,epochs=epochs, batch_size=512, validation_data=(X_vali, y_vali)).history\n",
    "\n",
    "\n",
    "alpha_range = [1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "\n",
    "\n",
    "error_train = []\n",
    "\n",
    "\n",
    "for alpha in alpha_range:\n",
    "    error_train.append(train_nn(x_train, y_train, x_val, y_val, alpha=alpha)['mse'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('choose alpha for neural network')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('mse')\n",
    "plt.bar([str(alpha) for alpha in alpha_range], error_train, color='green')"
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
=======
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02545383758842945,\n",
       " 0.025451207533478737,\n",
       " 0.025450779125094414,\n",
       " 0.02545202150940895,\n",
       " 0.02551654540002346]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "d = 2\n",
    "x = np.random.normal(size=(n,d))\n",
    "error = np.random.normal(size=(n,1))\n",
    "b = np.random.uniform(size=(d,1))\n",
    "\n",
    "### in order to avoid Perfect Separation, we need to add some noise\n",
    "y = x@b + error\n",
    "\n",
    "# y = list(map(lambda x: 1 if x > 0 else 0, y))\n",
    "\n",
    "# binary\n",
    "# y = np.array([0 if x <0 else 1  for x in y])\n",
    "# y = np.where(y<0, 0, 1)\n",
    "## 3 classes\n",
    "# y = np.array([0 if x < -1 else 1 if x < 1 else 2 for x in y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 of 2 with mse \n",
      "epoch 1 of 2 with mse \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
    "\n",
    "class neural:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def complie(self, cost = 'mse', matrix = 'mse'):\n",
    "        self.cost = cost\n",
    "        self.matrix = 'mse'\n",
    "        \n",
    "    def activation(self, z, function):\n",
    "        if function == 'linear' : return z\n",
    "        \n",
    "        if function == 'sigmod': return 1/(1+ np.exp(-z))\n",
    "\n",
    "    def deactivation(self, z, function):\n",
    "        if function == 'linear' : return z\n",
    "        if function == 'sigmod': \n",
    "            f = 1/(1+ np.exp(-z))\n",
    "            return f*(1-f)  \n",
    "        \n",
<<<<<<< HEAD
=======
    "    \n",
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
    "    def addBias(self, x):\n",
    "        ones = np.ones((x.shape[0], 1))\n",
    "        return np.hstack((ones,x)) \n",
    "        \n",
<<<<<<< HEAD
    "    def decost(self, pred, true):\n",
    "        if self.cost == 'mse':  return pred - true\n",
    "    \n",
    "    def dense(self, nodes = [], pred = [] , out = 'linear', functions = ['sigmod'], hidden = 2):\n",
    "        \n",
    "        \n",
    "        if out == 'linear': pred = 1\n",
    "        else: pred = len(np.unique(y))\n",
    "        \n",
    "        n, d = self.x.shape\n",
    "        \n",
    "        if not nodes:\n",
    "            nodes = [int(np.sqrt(d*pred))+1]\n",
    "        \n",
=======
    "        \n",
    "    def decost(self, pred, true):\n",
    "        if self.cost == 'mse':  return pred - true\n",
    "    \n",
    "    def dense(self, nodes = [32], pred = 3 , out = 'linear', functions = ['sigmod'], hidden = 2):\n",
    "        n, d = self.x.shape\n",
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
    "\n",
    "        while len(nodes) != hidden:\n",
    "            nodes.append(nodes[0])\n",
    "        \n",
<<<<<<< HEAD
    "        nodes = [d] + nodes + [pred]\n",
    "        \n",
    "        self.nodes = nodes\n",
    "        \n",
=======
    "        if out == 'linear': \n",
    "            nodes = [d] + nodes + [1]\n",
    "        else:\n",
    "            nodes = [d] + nodes + [pred]\n",
    "\n",
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
    "        while len(functions) != hidden:\n",
    "            functions.append(functions[0])\n",
    "\n",
    "        functions = ['input'] + functions+ [out]\n",
<<<<<<< HEAD
    "        \n",
    "        \n",
    "        ## numbers of layers is the numbers of hidden layer plus the input and output layer\n",
    "        \n",
=======
    "\n",
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
    "        layers = {number+1:[nodes[number], functions[number]] for number in range(hidden+2)}  \n",
    "\n",
    "        self.layers = layers\n",
    "        \n",
<<<<<<< HEAD
    "        \n",
    "        print(layers)\n",
    "        return layers\n",
    "\n",
    "    def make_weights(self, random_start):\n",
    "        \n",
    "        layers = self.layers\n",
    "        layer = len(layers)\n",
    "        \n",
    "        \n",
    "        ## dimension of weights is the dimension of input+1 (add bias) times the dimension of the next layer +1 \n",
    "        ## except the out layer\n",
    "        \n",
    "        if random_start == 0:\n",
    "            weights = {item:np.ones((layers[item][0]+1, layers[item+1][0]+1)) for item in range(1, layer-1)}\n",
    "            weights[layer-1] = np.ones((layers[layer-1][0]+1, 1))\n",
    "            return weights\n",
    "        \n",
    "        np.random.seed(random_start)\n",
    "        weights = {item:np.random.rand(layers[item][0]+1, layers[item+1][0]+1) for item in range(1, layer-1)}\n",
    "        weights[layer-1] = np.random.rand(layers[layer-1][0]+1, 1)\n",
    "        return weights\n",
    "        \n",
    "    def windows(self, batch):\n",
    "        ## random pop batch size of sampling\n",
    "        index = list(range(len(self.x)))\n",
    "        np.random.shuffle(index)\n",
    "\n",
    "        return self.x[index[:batch]], self.y[index[:batch]]\n",
    "    \n",
    "    def forward(self, weights, x = None):\n",
=======
    "        return layers\n",
    "\n",
    "    def make_weights(self):\n",
    "\n",
    "        layers = self.layers\n",
    "        layer = len(layers)\n",
    "        weights = {item:np.random.rand(layers[item][0]+1, layers[item+1][0]+1) for item in range(1, layer-1)}\n",
    "        weights[layer-1] = np.random.rand(layers[layer-1][0]+1, 1)\n",
    "        return weights\n",
    "    \n",
    "    def forward(self, weights, x = None ):\n",
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
    "        if x is None:\n",
    "            x = self.x\n",
    "            \n",
    "        next_input = [self.addBias(x)]\n",
    "        \n",
    "        for i in range(1, len(weights)+1):\n",
    "            next_input.append(next_input[i-1]@weights[i])\n",
    "        return next_input\n",
    "    \n",
    "\n",
    "    def ward(self, x, weight, error, function):\n",
<<<<<<< HEAD
    "        \n",
    "        ## there is no error for the input layer\n",
=======
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
    "        if function =='input':\n",
    "            return x.T@error, _\n",
    "        \n",
    "        derivate = self.deactivation(x, function)\n",
    "        return x.T@error, error@weight.T*derivate\n",
    "    \n",
<<<<<<< HEAD
    "    def back(self, next_input, weights, y, learning):\n",
=======
    "    def back(self, next_input, weights, y, learning = 0.01):\n",
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
    "        number = len(self.layers)\n",
    "        error ={number:self.decost(next_input[number-1], y)}\n",
    "        \n",
    "        update = []\n",
    "        for layer in range(number-1, 0, -1):\n",
    "            update, error[layer] = self.ward(next_input[layer-1], weights[layer], error[layer+1], self.layers[layer][1])\n",
<<<<<<< HEAD
    "            if np.isnan(update).any():\n",
    "                return weights, 0\n",
    "            weights[layer] -= learning*update\n",
    "            \n",
    "        return weights, np.sum(abs(update))\n",
    "    \n",
    "    def fit(self, threshold = 10e-3, batch = 256, epochs = 10 ,random_start = 0 , learning = []):\n",
    "        \n",
    "        weights = self.make_weights(random_start)\n",
    "        \n",
    "        \n",
    "        if not learning:\n",
    "            learning = 1/np.power(2, len(self.layers)+ self.nodes[1]+self.x.shape[1])\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            ## automatically reduce the learning step\n",
    "            learning = learning /(epoch+1)\n",
=======
    "\n",
    "            weights[layer] -= update\n",
    "            \n",
    "        return weights, np.sum(abs(update))\n",
    "                               \n",
    "    def windows(self, batch):\n",
    "        index = list(range(len(self.x)))\n",
    "        np.random.shuffle(index)\n",
    "\n",
    "        return self.x[index[:batch]], self.y[index[:batch]]\n",
    "    \n",
    "    \n",
    "    def fit(self, threshold = 10e-5, batch = 64, epochs = 2):\n",
    "        \n",
    "        weights = self.make_weights()\n",
    "                               \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            \n",
    "            learning = 1/(1+ epoch)\n",
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
    "            \n",
    "            x, y = self.windows(batch)\n",
    "                               \n",
    "            next_input = self.forward(weights, x)\n",
<<<<<<< HEAD
    "            print('epoch {epoch} of {epochs} with mse {mse}'.format(epoch = epoch+1, epochs = epochs, mse = self.mse(next_input[-1], y) ))\n",
    "            weights, update = self.back(next_input, weights, y, learning)\n",
    "            \n",
    "            if update <= threshold: return\n",
    "            \n",
    "            self.weights = weights\n",
    "            \n",
=======
    "            print('epoch {epoch} of {epochs} with mse {mse}'.format(epoch = epoch, epochs = epochs ))\n",
    "            weights, update = self.back(next_input, weights, y)\n",
    "            \n",
    "            self.weights = weights\n",
    "            \n",
    "            if update <= threshold:\n",
    "                return epochs\n",
    "            \n",
    "        return epochs\n",
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
    "    \n",
    "    def predict(self, x):\n",
    "        pred = self.forward(self.weights, x)[-1]\n",
    "        return pred\n",
<<<<<<< HEAD
    "    \n",
    "    def mse(self,pred, true):\n",
    "        error = pred - true\n",
    "        return error.T@error/len(error)\n"
=======
    "\n",
    "# model = neural(x_train.values, y_train.values.reshape(-1,1))\n",
    "model = neural(x, y )\n",
    "model.dense()\n",
    "model.complie(cost = 'mse', matrix = 'mse')\n",
    "model.fit()"
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [10, 'input'], 2: [4, 'sigmod'], 3: [4, 'sigmod'], 4: [1, 'linear']}\n",
      "epoch 1 of 10 with mse [[6394.44779124]]\n",
      "epoch 2 of 10 with mse [[546.26132455]]\n",
      "epoch 3 of 10 with mse [[95.655366]]\n",
      "epoch 4 of 10 with mse [[63.22396424]]\n",
      "epoch 5 of 10 with mse [[53.96255601]]\n",
      "epoch 6 of 10 with mse [[59.48561139]]\n",
      "epoch 7 of 10 with mse [[43.08762748]]\n",
      "epoch 8 of 10 with mse [[46.9129681]]\n",
      "epoch 9 of 10 with mse [[52.32381729]]\n",
      "epoch 10 of 10 with mse [[44.88919778]]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = neural(train_x, train_y)\n",
    "model.dense()\n",
    "model.complie(cost = 'mse', matrix = 'mse')\n",
    "model.fit(random_start = 0)"
=======
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.52920141e+32],\n",
       "       [ 3.15857836e+32],\n",
       "       [-6.31118164e+32],\n",
       "       [ 8.10807729e+32],\n",
       "       [ 3.03821791e+32],\n",
       "       [-8.06078300e+32],\n",
       "       [ 1.75358647e+32],\n",
       "       [ 2.29133222e+33],\n",
       "       [ 5.73463504e+32],\n",
       "       [ 3.09763790e+32]])"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mse\n",
    "pred = model.predict(test_x)\n",
    "my_mse = np.square(pred - test_y).sum()/len(pred)\n",
    "end = time.time()\n",
    "my_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "start = time.time()\n",
    "y_train = train_y.T\n",
    "regr = MLPRegressor().fit(train_x, train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = regr.predict(test_x)\n",
    "sk_mse = np.square(pred.reshape(-1,1) - test_y).sum()/len(pred)\n",
    "end = time.time()\n",
    "sk_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
=======
   "execution_count": 445,
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "Text(0.5, 1.0, 'MSE')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(['my','sk'],[my_mse, sk_mse],'ro')\n",
    "plt.title('MSE')"
=======
       "array([[ 0.18516602],\n",
       "       [ 0.70102952],\n",
       "       [-2.35010989],\n",
       "       [-0.30879426],\n",
       "       [-0.10433223],\n",
       "       [ 0.15728613],\n",
       "       [-1.07966882],\n",
       "       [-1.09421749],\n",
       "       [ 2.30699693],\n",
       "       [-0.37303134]])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 of 2 with mse \n",
      "epoch 1 of 2 with mse \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = neural(x_train.values, y_train.values.reshape(-1,1))\n",
    "model.dense()\n",
    "model.complie(cost = 'mse', matrix = 'mse')\n",
    "model.fit()"
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 442,
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "Text(0.5, 1.0, 'Time')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(['my','sk'],[my_time, sk_time],'bo')\n",
    "plt.title('Time')"
=======
       "array([[nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       ...,\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan]])"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
>>>>>>> 27dc72bf56eba6ef0435dd9625fa62998278179c
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
