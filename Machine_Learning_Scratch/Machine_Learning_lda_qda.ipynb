{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(size=(10000,4))\n",
    "error = np.random.normal(size=(10000,1))\n",
    "b = np.random.uniform(size=(4,1))\n",
    "\n",
    "### in order to avoid Perfect Separation, we need to add some noise\n",
    "y = x@b + error\n",
    "\n",
    "# y = list(map(lambda x: 1 if x > 0 else 0, y))\n",
    "\n",
    "# binary\n",
    "# y = np.array([0 if x <0 else 1  for x in y])\n",
    "\n",
    "## 3 classes\n",
    "y = np.array([0 if x < -1 else 1 if x < 1 else 2 for x in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([6.000e+00, 7.600e+01, 5.220e+02, 1.837e+03, 3.176e+03, 2.805e+03,\n",
       "         1.224e+03, 3.160e+02, 3.600e+01, 2.000e+00]),\n",
       "  array([4.000e+00, 7.500e+01, 5.060e+02, 1.785e+03, 3.153e+03, 2.832e+03,\n",
       "         1.323e+03, 2.940e+02, 2.600e+01, 2.000e+00]),\n",
       "  array([8.000e+00, 8.800e+01, 5.060e+02, 1.894e+03, 3.111e+03, 2.801e+03,\n",
       "         1.264e+03, 2.930e+02, 3.400e+01, 1.000e+00]),\n",
       "  array([9.000e+00, 9.100e+01, 5.080e+02, 1.855e+03, 3.116e+03, 2.818e+03,\n",
       "         1.294e+03, 2.750e+02, 3.200e+01, 2.000e+00])],\n",
       " array([-4.10035173, -3.25181386, -2.40327599, -1.55473811, -0.70620024,\n",
       "         0.14233763,  0.9908755 ,  1.83941337,  2.68795124,  3.53648911,\n",
       "         4.38502698]),\n",
       " <a list of 4 Lists of Patches objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generate_process:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y    \n",
    "        \n",
    "    def split(self, rate = 0.7, random_state = 1024, scale = False):\n",
    "        ## Feature scaling is used to normalize the range of independent variables or features of data\n",
    "        if scale:\n",
    "            self.x = (self.x - np.mean(self.x))/x.std()\n",
    "        \n",
    "        n = len(self.y)\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "        ##randomly spilte data into 70% train and 30% test\n",
    "        index = list(range(n))\n",
    "        np.random.shuffle(index)\n",
    "        train = index[:int(rate*n)]\n",
    "        test = index[int(rate*n):]\n",
    "        \n",
    "        self.train_x = self.x[train]\n",
    "        self.test_x = self.x[test]\n",
    "        self.train_y = self.y[train]\n",
    "        self.test_y = self.y[test]\n",
    "        \n",
    "        return self.train_x, self.test_x, self.train_y, self.test_y\n",
    "    \n",
    "train_x, test_x, train_y, test_y = data_generate_process(x, y ).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def lda(self, x = None, y = None):\n",
    "        if x is None:\n",
    "            x = self.x\n",
    "        if y is None:\n",
    "            y = self.y\n",
    "            \n",
    "        ## vector of k classes in an ascending order\n",
    "        groups = np.unique(y)\n",
    "        self.groups = groups\n",
    "        \n",
    "        ##create N by k (classes) matrix\n",
    "        likehood = np.zeros((len(x), len(groups))) \n",
    "        \n",
    "        means = {}\n",
    "        covariances = {}\n",
    "        indexs = {}\n",
    "        \n",
    "        for group in groups:\n",
    "            ##get the index of all the x that belong to k classes\n",
    "            index = np.where(y == groups[group])[0]\n",
    "            indexs[group] = index\n",
    "            \n",
    "            means[group] = np.mean(x[index],axis = 0)\n",
    "            \n",
    "            covariances[group] = np.cov(x.T)\n",
    "            \n",
    "        self.index = indexs\n",
    "        self.mean = means\n",
    "        self.covariance = covariances \n",
    "\n",
    "    def lda_predict(self, x, mean = None, covariance = None):\n",
    "        if covariance is None:\n",
    "            covariance = self.covariance\n",
    "\n",
    "        if mean is None:\n",
    "            mean = self.mean\n",
    "            \n",
    "        \n",
    "        ##create N by k (classes) matrix\n",
    "        likehood = np.zeros((len(x), len(self.groups)))\n",
    "#         print(likehood.shape)\n",
    "        for group in self.groups:\n",
    "            mean = self.mean[group]\n",
    "            covariance = self.covariance[group]\n",
    "            covariance_inv = np.linalg.inv(covariance)\n",
    "            ## calcuate how many points belong to kth class\n",
    "            ## that's the probably\n",
    "            points = len(self.index[group])\n",
    "            \n",
    "            probablity = x@covariance_inv@mean - 0.5*mean.T@covariance_inv@mean +np.log(points)\n",
    "                                \n",
    "            likehood[:,group] = probablity\n",
    "            \n",
    "        ##get the index of max likehood for each observations\n",
    "            self.labels = likehood.argmax(axis = 1)\n",
    "        return self.labels\n",
    "            \n",
    "    def qda(self, x = None, y = None):\n",
    "        if x is None:\n",
    "            x = self.x\n",
    "        if y is None:\n",
    "            y = self.y\n",
    "            \n",
    "        ## vector of k classes in an ascending order\n",
    "        groups = np.unique(y)\n",
    "        self.groups = groups\n",
    "        \n",
    "        ##create N by k (classes) matrix\n",
    "        likehood = np.zeros((len(x), len(groups)))  \n",
    "        \n",
    "        means = {}\n",
    "        covariances = {}\n",
    "        indexs = {}\n",
    "        \n",
    "        for group in groups:\n",
    "            ##get the index of all the x that belong to k classes\n",
    "            index = np.where(y == groups[group])[0]\n",
    "            indexs[group] = index\n",
    "            \n",
    "             ## calcuate mean & covariance matrix of all the x that belong to k classes\n",
    "            means[group] = np.mean(x[index],axis = 0)\n",
    "            \n",
    "            covariances[group] = np.cov(x[index].T)\n",
    "        \n",
    "        self.index = indexs\n",
    "        self.mean = means\n",
    "        self.covariance = covariances\n",
    " \n",
    "    def qda_predict(self, x, mean = None, covariance = None):\n",
    "        if covariance is None:\n",
    "            covariance = self.covariance\n",
    "\n",
    "        if mean is None:\n",
    "            mean = self.mean\n",
    "            \n",
    "        \n",
    "        ##create N by k (classes) matrix\n",
    "        likehood = np.zeros((len(x), len(self.groups)))\n",
    "#         print(likehood.shape)\n",
    "        for group in self.groups:\n",
    "            mean = self.mean[group]\n",
    "            covariance = self.covariance[group]\n",
    "            \n",
    "            ## calcuate how many points belong to kth class\n",
    "            ## that's the probably\n",
    "            points = len(self.index[group])\n",
    "            \n",
    "            shift = x - mean\n",
    "            ## create a diag matrix of covariance with all 0 expcet the diagonal\n",
    "            scale = np.diagflat(np.diag(covariance))\n",
    "            scale_inv = np.linalg.inv(scale)\n",
    "            det = np.linalg.det(scale)\n",
    "            ## log(points/N), N can't be obmitted\n",
    "#             probablity = np.log(points)- 0.5*np.log(np.linalg.det(scale))- 0.5*np.diag(shift@np.linalg.inv(scale)@shift.T)\n",
    "            probablity = np.log(points) - 0.5*np.log(det ) - 0.5*np.diag(shift@scale_inv@shift.T)\n",
    "                                \n",
    "            likehood[:,group] = probablity\n",
    "            \n",
    "        ##get the index of max likehood for each observations\n",
    "            self.labels = likehood.argmax(axis = 1)\n",
    "        return self.labels\n",
    "\n",
    "    def confusion_matirx(self, test, pred):\n",
    "        groups = np.unique(test_y)\n",
    "        \n",
    "        index_true = {i:[] for i in groups}\n",
    "\n",
    "        ## index of each class of true labels\n",
    "        for index, label in enumerate(test_y):\n",
    "            index_true[label].append(index)\n",
    "\n",
    "        counts = []\n",
    "        ## groupby classes of true labels, count the numbers for each class in predict\n",
    "        for group in groups:\n",
    "            count = {i:0 for i in groups}\n",
    "            for label in pred[index_true[group]]:\n",
    "                count[label] += 1\n",
    "            counts.append(count)\n",
    "\n",
    "        matirx = pd.DataFrame(counts)\n",
    "        columns_names =  ['predict '+str(group) for group in groups]\n",
    "        matirx.columns = columns_names\n",
    "        \n",
    "        self.matirx = matirx\n",
    "        return  self.matirx\n",
    "        ## accuracy\n",
    "    def performance(self, test, pred):\n",
    "        \n",
    "        mat = self.confusion_matirx(test, pred).values\n",
    "\n",
    "\n",
    "        self.accuracy = np.diag(mat).sum()/mat.sum()\n",
    "        \n",
    "        self.precision = np.diag(mat) / np.sum(mat, axis = 0) \n",
    "        self.recall = np.diag(mat)/ np.sum(mat, axis = 1) \n",
    "        \n",
    "        self.fmeasure = [x*y/(x+y) if (x+y) >0 else 0 for x, y in zip(self.precision,self.recall)]\n",
    "\n",
    "\n",
    "        df = pd.DataFrame([ self.precision, self.recall, self.fmeasure]).T\n",
    "        df.columns = ['precision', 'recall', 'f1-score']\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis (LDA)\n",
    "# https://en.wikipedia.org/wiki/Linear_discriminant_analysis\n",
    "# Assume all $\\Sigma_k == \\Sigma_l $\n",
    "# Final Decision Scores\n",
    "# $ \\delta_k(x) = X\\Sigma^{-1}\\mu - 1/2\\mu\\Sigma^{-1}\\mu + \\log_k(probability)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. My solution to LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.766272</td>\n",
       "      <td>0.358726</td>\n",
       "      <td>0.244340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.574144</td>\n",
       "      <td>0.904192</td>\n",
       "      <td>0.351163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.772881</td>\n",
       "      <td>0.294194</td>\n",
       "      <td>0.213084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall  f1-score\n",
       "0   0.766272  0.358726  0.244340\n",
       "1   0.574144  0.904192  0.351163\n",
       "2   0.772881  0.294194  0.213084"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ulric_lda = model(train_x, train_y)\n",
    "ulric_lda.lda()\n",
    "lda_pred = ulric_lda.lda_predict(test_x)\n",
    "ulric_lda.performance(test_y, lda_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict 0</th>\n",
       "      <th>predict 1</th>\n",
       "      <th>predict 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259</td>\n",
       "      <td>463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>1359</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>545</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predict 0  predict 1  predict 2\n",
       "0        259        463          0\n",
       "1         77       1359         67\n",
       "2          2        545        228"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ulric_lda.confusion_matirx(test_y, lda_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Sklearn solution to LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.676     0.506     0.578       722\n",
      "           1      0.606     0.779     0.682      1503\n",
      "           2      0.681     0.465     0.552       775\n",
      "\n",
      "   micro avg      0.632     0.632     0.632      3000\n",
      "   macro avg      0.654     0.583     0.604      3000\n",
      "weighted avg      0.642     0.632     0.624      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "lda = LinearDiscriminantAnalysis().fit(train_x, train_y.ravel()).predict(test_x)\n",
    "print(classification_report(test_y, lda, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 365  353    4]\n",
      " [ 167 1171  165]\n",
      " [   8  407  360]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_y, lda))\n",
    "## almost sane to my solution of LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic discriminant analysis\n",
    "https://en.wikipedia.org/wiki/Quadratic_classifier#Quadratic_discriminant_analysis\n",
    "# relax $\\Sigma_k == \\Sigma_l $\n",
    "# Final Decision Scores for all x \n",
    "## $ \\delta_k(x) = -1/2(X-\\mu_k)\\Sigma_k^{-1}(x-\\mu_k) - 1/2\\log(\\det \\Sigma )+ \\log_k(probability)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.My solution to QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.700651</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.273035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.597022</td>\n",
       "      <td>0.827013</td>\n",
       "      <td>0.346722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.717724</td>\n",
       "      <td>0.423226</td>\n",
       "      <td>0.266234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall  f1-score\n",
       "0   0.700651  0.447368  0.273035\n",
       "1   0.597022  0.827013  0.346722\n",
       "2   0.717724  0.423226  0.266234"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ulric_qda = model(train_x, train_y)\n",
    "ulric_qda.qda()\n",
    "qda_pred = ulric_qda.qda_predict(test_x)\n",
    "ulric_qda.performance(test_y, qda_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict 0</th>\n",
       "      <th>predict 1</th>\n",
       "      <th>predict 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>323</td>\n",
       "      <td>397</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>133</td>\n",
       "      <td>1243</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>442</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predict 0  predict 1  predict 2\n",
       "0        323        397          2\n",
       "1        133       1243        127\n",
       "2          5        442        328"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ulric_qda.confusion_matirx(test_y, qda_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 SKlearn solution to QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.675     0.501     0.576       722\n",
      "           1      0.604     0.783     0.682      1503\n",
      "           2      0.680     0.453     0.544       775\n",
      "\n",
      "   micro avg      0.630     0.630     0.630      3000\n",
      "   macro avg      0.653     0.579     0.600      3000\n",
      "weighted avg      0.641     0.630     0.621      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis().fit(train_x, train_y.ravel()).predict(test_x)\n",
    "print(classification_report(test_y, qda, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 362  356    4]\n",
      " [ 165 1177  161]\n",
      " [   9  415  351]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_y,qda))\n",
    "\n",
    "## almost as my solutions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
