{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## random generate numbers\n",
    "n = 10000\n",
    "d = 10\n",
    "n = 10000\n",
    "d = 10\n",
    "x = np.random.normal(size=(n,d))\n",
    "error = np.random.normal(size=(n,1))\n",
    "\n",
    "b = np.random.uniform(size=(d,1))\n",
    "\n",
    "### in order to avoid Perfect Separation, we need to add some noise\n",
    "y = x@b + error\n",
    "\n",
    "# y = list(map(lambda x: 1 if x > 0 else 0, y))\n",
    "\n",
    "# binary\n",
    "# y = np.array([0 if x <0 else 1  for x in y])\n",
    "\n",
    "## 3 classes\n",
    "y = np.array([0 if x < -1 else 1 if x < 1 else 2 for x in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([4.000e+00, 7.400e+01, 5.700e+02, 2.086e+03, 3.461e+03, 2.647e+03,\n",
       "         9.510e+02, 1.860e+02, 2.000e+01, 1.000e+00]),\n",
       "  array([6.000e+00, 7.700e+01, 6.260e+02, 2.043e+03, 3.384e+03, 2.695e+03,\n",
       "         9.960e+02, 1.630e+02, 9.000e+00, 1.000e+00]),\n",
       "  array([   5.,   86.,  616., 2088., 3411., 2641.,  961.,  180.,   12.,\n",
       "            0.]),\n",
       "  array([   4.,   87.,  614., 2015., 3452., 2650.,  986.,  176.,   16.,\n",
       "            0.]),\n",
       "  array([   7.,   94.,  582., 2089., 3340., 2700.,  989.,  183.,   16.,\n",
       "            0.]),\n",
       "  array([9.000e+00, 8.700e+01, 5.920e+02, 2.120e+03, 3.292e+03, 2.730e+03,\n",
       "         9.880e+02, 1.730e+02, 8.000e+00, 1.000e+00]),\n",
       "  array([   5.,  105.,  579., 2129., 3381., 2580., 1008.,  194.,   19.,\n",
       "            0.]),\n",
       "  array([  12.,   91.,  635., 2091., 3356., 2662.,  975.,  169.,    9.,\n",
       "            0.]),\n",
       "  array([5.000e+00, 7.900e+01, 5.950e+02, 2.124e+03, 3.327e+03, 2.653e+03,\n",
       "         1.032e+03, 1.720e+02, 1.000e+01, 3.000e+00]),\n",
       "  array([3.000e+00, 7.700e+01, 6.130e+02, 2.170e+03, 3.311e+03, 2.632e+03,\n",
       "         9.970e+02, 1.850e+02, 1.000e+01, 2.000e+00])],\n",
       " array([-4.14813501, -3.25940623, -2.37067745, -1.48194867, -0.5932199 ,\n",
       "         0.29550888,  1.18423766,  2.07296644,  2.96169522,  3.850424  ,\n",
       "         4.73915278]),\n",
       " <a list of 10 Lists of Patches objects>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generate_process:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y    \n",
    "        \n",
    "    def split(self, rate = 0.7, random_state = 1024, scale = False):\n",
    "        ## Feature scaling is used to normalize the range of independent variables or features of data\n",
    "        if scale:\n",
    "            self.x = (self.x - np.mean(self.x))/x.std()\n",
    "        \n",
    "        n = len(self.y)\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "        ##randomly spilte data into 70% train and 30% test\n",
    "        index = list(range(n))\n",
    "        np.random.shuffle(index)\n",
    "        train = index[:int(rate*n)]\n",
    "        test = index[int(rate*n):]\n",
    "        \n",
    "        self.train_x = self.x[train]\n",
    "        self.test_x = self.x[test]\n",
    "        self.train_y = self.y[train]\n",
    "        self.test_y = self.y[test]\n",
    "        \n",
    "        return self.train_x, self.test_x, self.train_y, self.test_y\n",
    "    \n",
    "train_x, test_x, train_y, test_y = data_generate_process(x, y ).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def lda(self, x = None, y = None):\n",
    "        if x is None:\n",
    "            x = self.x\n",
    "        if y is None:\n",
    "            y = self.y\n",
    "            \n",
    "        ## vector of k classes in an ascending order\n",
    "        groups = np.unique(y)\n",
    "        self.groups = groups\n",
    "        \n",
    "        ##create N by k (classes) matrix\n",
    "        likehood = np.zeros((len(x), len(groups))) \n",
    "        \n",
    "        means = {}\n",
    "        covariances = {}\n",
    "        indexs = {}\n",
    "        \n",
    "        for group in groups:\n",
    "            ##get the index of all the x that belong to k classes\n",
    "            index = np.where(y == groups[group])[0]\n",
    "            indexs[group] = index\n",
    "            \n",
    "            means[group] = np.mean(x[index],axis = 0)\n",
    "            \n",
    "            covariances[group] = np.cov(x.T)\n",
    "            \n",
    "        self.index = indexs\n",
    "        self.mean = means\n",
    "        self.covariance = covariances \n",
    "\n",
    "    def lda_predict(self, x, mean = None, covariance = None):\n",
    "        if covariance is None:\n",
    "            covariance = self.covariance\n",
    "\n",
    "        if mean is None:\n",
    "            mean = self.mean\n",
    "            \n",
    "        \n",
    "        ##create N by k (classes) matrix\n",
    "        likehood = np.zeros((len(x), len(self.groups)))\n",
    "#         print(likehood.shape)\n",
    "        for group in self.groups:\n",
    "            mean = self.mean[group]\n",
    "            covariance = self.covariance[group]\n",
    "            covariance_inv = np.linalg.inv(covariance)\n",
    "            ## calcuate how many points belong to kth class\n",
    "            ## that's the probably\n",
    "            points = len(self.index[group])\n",
    "            \n",
    "            probablity = x@covariance_inv@mean - 0.5*mean.T@covariance_inv@mean +np.log(points)\n",
    "                                \n",
    "            likehood[:,group] = probablity\n",
    "            \n",
    "        ##get the index of max likehood for each observations\n",
    "            self.labels = likehood.argmax(axis = 1)\n",
    "        return self.labels\n",
    "            \n",
    "    def qda(self, x = None, y = None):\n",
    "        if x is None:\n",
    "            x = self.x\n",
    "        if y is None:\n",
    "            y = self.y\n",
    "            \n",
    "        ## vector of k classes in an ascending order\n",
    "        groups = np.unique(y)\n",
    "        self.groups = groups\n",
    "        \n",
    "        ##create N by k (classes) matrix\n",
    "        likehood = np.zeros((len(x), len(groups)))  \n",
    "        \n",
    "        means = {}\n",
    "        covariances = {}\n",
    "        indexs = {}\n",
    "        \n",
    "        for group in groups:\n",
    "            ##get the index of all the x that belong to k classes\n",
    "            index = np.where(y == groups[group])[0]\n",
    "            indexs[group] = index\n",
    "            \n",
    "             ## calcuate mean & covariance matrix of all the x that belong to k classes\n",
    "            means[group] = np.mean(x[index],axis = 0)\n",
    "            \n",
    "            covariances[group] = np.cov(x[index].T)\n",
    "        \n",
    "        self.index = indexs\n",
    "        self.mean = means\n",
    "        self.covariance = covariances\n",
    " \n",
    "    def qda_predict(self, x, mean = None, covariance = None):\n",
    "        if covariance is None:\n",
    "            covariance = self.covariance\n",
    "\n",
    "        if mean is None:\n",
    "            mean = self.mean\n",
    "            \n",
    "        \n",
    "        ##create N by k (classes) matrix\n",
    "        likehood = np.zeros((len(x), len(self.groups)))\n",
    "#         print(likehood.shape)\n",
    "        for group in self.groups:\n",
    "            mean = self.mean[group]\n",
    "            covariance = self.covariance[group]\n",
    "            \n",
    "            ## calcuate how many points belong to kth class\n",
    "            ## that's the probably\n",
    "            points = len(self.index[group])\n",
    "            \n",
    "            shift = x - mean\n",
    "            ## create a diag matrix of covariance with all 0 expcet the diagonal\n",
    "            scale = np.diagflat(np.diag(covariance))\n",
    "            scale_inv = np.linalg.inv(scale)\n",
    "            det = np.linalg.det(scale)\n",
    "            ## log(points/N), N can't be obmitted\n",
    "#             probablity = np.log(points)- 0.5*np.log(np.linalg.det(scale))- 0.5*np.diag(shift@np.linalg.inv(scale)@shift.T)\n",
    "            probablity = np.log(points) - 0.5*np.log(det ) - 0.5*np.diag(shift@scale_inv@shift.T)\n",
    "                                \n",
    "            likehood[:,group] = probablity\n",
    "            \n",
    "        ##get the index of max likehood for each observations\n",
    "            self.labels = likehood.argmax(axis = 1)\n",
    "        return self.labels\n",
    "\n",
    "    def confusion_matirx(self, test, pred):\n",
    "        groups = np.unique(test_y)\n",
    "        \n",
    "        index_true = {i:[] for i in groups}\n",
    "\n",
    "        ## index of each class of true labels\n",
    "        for index, label in enumerate(test_y):\n",
    "            index_true[label].append(index)\n",
    "\n",
    "        counts = []\n",
    "        ## groupby classes of true labels, count the numbers for each class in predict\n",
    "        for group in groups:\n",
    "            count = {i:0 for i in groups}\n",
    "            for label in pred[index_true[group]]:\n",
    "                count[label] += 1\n",
    "            counts.append(count)\n",
    "\n",
    "        matirx = pd.DataFrame(counts)\n",
    "        columns_names =  ['predict '+str(group) for group in groups]\n",
    "        matirx.columns = columns_names\n",
    "        \n",
    "        self.matirx = matirx\n",
    "        return  self.matirx\n",
    "        ## accuracy\n",
    "    def performance(self, test, pred):\n",
    "        \n",
    "        mat = self.confusion_matirx(test, pred).values\n",
    "\n",
    "\n",
    "        self.accuracy = np.diag(mat).sum()/mat.sum()\n",
    "        \n",
    "        self.precision = np.diag(mat) / np.sum(mat, axis = 0) \n",
    "        self.recall = np.diag(mat)/ np.sum(mat, axis = 1) \n",
    "        \n",
    "        self.fmeasure = [x*y/(x+y) if (x+y) >0 else 0 for x, y in zip(self.precision,self.recall)]\n",
    "\n",
    "\n",
    "        df = pd.DataFrame([ self.precision, self.recall, self.fmeasure]).T\n",
    "        df.columns = ['precision', 'recall', 'f1-score']\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis (LDA)\n",
    "# https://en.wikipedia.org/wiki/Linear_discriminant_analysis\n",
    "# Assume all $\\Sigma_k == \\Sigma_l $\n",
    "# Final Decision Scores\n",
    "# $ \\delta_k(x) = X\\Sigma^{-1}\\mu - 1/2\\mu\\Sigma^{-1}\\mu + \\log_k(probability)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. My solution to LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.824407</td>\n",
       "      <td>0.863051</td>\n",
       "      <td>0.421643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.611364</td>\n",
       "      <td>0.593164</td>\n",
       "      <td>0.301063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.814475</td>\n",
       "      <td>0.795025</td>\n",
       "      <td>0.402316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall  f1-score\n",
       "0   0.824407  0.863051  0.421643\n",
       "1   0.611364  0.593164  0.301063\n",
       "2   0.814475  0.795025  0.402316"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "ulric_lda = model(train_x, train_y)\n",
    "ulric_lda.lda()\n",
    "lda_pred = ulric_lda.lda_predict(test_x)\n",
    "ulric_lda.performance(test_y, lda_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   predict 0  predict 1  predict 2\n",
      "0        939        144          5\n",
      "1        192        538        177\n",
      "2          8        198        799\n"
     ]
    }
   ],
   "source": [
    "print(ulric_lda.confusion_matirx(test_y, lda_pred))\n",
    "end = time.time()\n",
    "my_lda = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Sklearn solution to LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.844     0.829     0.836      1088\n",
      "           1      0.593     0.655     0.622       907\n",
      "           2      0.835     0.772     0.802      1005\n",
      "\n",
      "    accuracy                          0.757      3000\n",
      "   macro avg      0.757     0.752     0.754      3000\n",
      "weighted avg      0.765     0.757     0.760      3000\n",
      "\n",
      "[[902 183   3]\n",
      " [163 594 150]\n",
      " [  4 225 776]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "start = time.time()\n",
    "lda = LinearDiscriminantAnalysis().fit(train_x, train_y.ravel()).predict(test_x)\n",
    "print(classification_report(test_y, lda, digits=3))\n",
    "print(confusion_matrix(test_y, lda))\n",
    "end = time.time()\n",
    "sk_lda = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic discriminant analysis\n",
    "https://en.wikipedia.org/wiki/Quadratic_classifier#Quadratic_discriminant_analysis\n",
    "# relax $\\Sigma_k == \\Sigma_l $\n",
    "# Final Decision Scores for all x \n",
    "## $ \\delta_k(x) = -1/2(X-\\mu_k)\\Sigma_k^{-1}(x-\\mu_k) - 1/2\\log(\\det \\Sigma )+ \\log_k(probability)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.My solution to QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.820604</td>\n",
       "      <td>0.849265</td>\n",
       "      <td>0.417344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.601545</td>\n",
       "      <td>0.600882</td>\n",
       "      <td>0.300607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.821281</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.402940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall  f1-score\n",
       "0   0.820604  0.849265  0.417344\n",
       "1   0.601545  0.600882  0.300607\n",
       "2   0.821281  0.791045  0.402940"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ulric_qda = model(train_x, train_y)\n",
    "ulric_qda.qda()\n",
    "qda_pred = ulric_qda.qda_predict(test_x)\n",
    "ulric_qda.performance(test_y, qda_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict 0</th>\n",
       "      <th>predict 1</th>\n",
       "      <th>predict 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>924</td>\n",
       "      <td>159</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194</td>\n",
       "      <td>545</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>202</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predict 0  predict 1  predict 2\n",
       "0        924        159          5\n",
       "1        194        545        168\n",
       "2          8        202        795"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ulric_qda.confusion_matirx(test_y, qda_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 SKlearn solution to QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.855     0.815     0.834      1088\n",
      "           1      0.581     0.681     0.627       907\n",
      "           2      0.840     0.751     0.793      1005\n",
      "\n",
      "    accuracy                          0.753      3000\n",
      "   macro avg      0.759     0.749     0.752      3000\n",
      "weighted avg      0.767     0.753     0.758      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "qda = QuadraticDiscriminantAnalysis().fit(train_x, train_y.ravel()).predict(test_x)\n",
    "print(classification_report(test_y, qda, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[887 198   3]\n",
      " [148 618 141]\n",
      " [  3 247 755]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_y,qda))\n",
    "\n",
    "## almost as my solutions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
