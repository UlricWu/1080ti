{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "import time\n",
    "# import cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.power(10,6)\n",
    "d = 10\n",
    "x = np.random.normal(size=(n,d))\n",
    "error = np.random.normal(size=(n,1))\n",
    "b = np.random.uniform(size=(d,1))\n",
    "\n",
    "### in order to avoid Perfect Separation, we need to add some noise\n",
    "y = x@b + error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generate_process:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y    \n",
    "        \n",
    "    def split(self, rate = 0.7, random_state = 1024, scale = False):\n",
    "        ## Feature scaling is used to normalize the range of independent variables or features of data\n",
    "        if scale:\n",
    "            self.x = (self.x - np.mean(self.x))/x.std()\n",
    "        \n",
    "        n = len(self.y)\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "        ##randomly spilte data into 70% train and 30% test\n",
    "        index = list(range(n))\n",
    "        np.random.shuffle(index)\n",
    "        train = index[:int(rate*n)]\n",
    "        test = index[int(rate*n):]\n",
    "        \n",
    "        self.train_x = self.x[train]\n",
    "        self.test_x = self.x[test]\n",
    "        self.train_y = self.y[train]\n",
    "        self.test_y = self.y[test]\n",
    "        \n",
    "        return self.train_x, self.test_x, self.train_y, self.test_y\n",
    "    \n",
    "train_x, test_x, train_y, test_y = data_generate_process(x, y).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  $ cost = 1/(pred - true)^2 \\; $  for Regression\n",
    "## $ \\theta_L$ = pred - true \n",
    "## $ \\theta_i = (theta_(i+1)). \\dot Weight_i * Activation'(alpha_i) $\n",
    "##    $ update_i = (\\alpha_i.T) . \\dot (\\theta_(i+1)) $\n",
    "##  $ weight_i.shape = (\\alpha_i.shape[1]+1, \\alpha_i.shape[1]+1) $\n",
    "##  $ weight_L.shape = (\\alpha_(L-1).shape[1]+1, 1 \\; or  \\;labels) $\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class neural:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def complie(self, cost = 'mse', matrix = 'mse'):\n",
    "        self.cost = cost\n",
    "        self.matrix = 'mse'\n",
    "        \n",
    "    def activation(self, z, function):\n",
    "        if function == 'linear' : return z\n",
    "        \n",
    "        if function == 'sigmod': return 1/(1+ np.exp(-z))\n",
    "\n",
    "    def deactivation(self, z, function):\n",
    "        if function == 'linear' : return z\n",
    "        if function == 'sigmod': \n",
    "            f = 1/(1+ np.exp(-z))\n",
    "            return f*(1-f)  \n",
    "        \n",
    "    def addBias(self, x):\n",
    "        ones = np.ones((x.shape[0], 1))\n",
    "        return np.hstack((ones,x)) \n",
    "        \n",
    "    def decost(self, pred, true):\n",
    "        if self.cost == 'mse':  return pred - true\n",
    "    \n",
    "    def dense(self, nodes = [], pred = [] , out = 'linear', functions = ['sigmod'], hidden = 2):\n",
    "        \n",
    "        \n",
    "        if out == 'linear': pred = 1\n",
    "        else: pred = len(np.unique(y))\n",
    "        \n",
    "        n, d = self.x.shape\n",
    "        \n",
    "        if not nodes:\n",
    "            nodes = [int(np.sqrt(d*pred))+1]\n",
    "        \n",
    "\n",
    "        while len(nodes) != hidden:\n",
    "            nodes.append(nodes[0])\n",
    "        \n",
    "        nodes = [d] + nodes + [pred]\n",
    "        \n",
    "        self.nodes = nodes\n",
    "        \n",
    "        while len(functions) != hidden:\n",
    "            functions.append(functions[0])\n",
    "\n",
    "        functions = ['input'] + functions+ [out]\n",
    "        \n",
    "        \n",
    "        ## numbers of layers is the numbers of hidden layer plus the input and output layer\n",
    "        \n",
    "        layers = {number+1:[nodes[number], functions[number]] for number in range(hidden+2)}  \n",
    "\n",
    "        self.layers = layers\n",
    "        \n",
    "        \n",
    "        print(layers)\n",
    "        return layers\n",
    "\n",
    "    def make_weights(self, random_start):\n",
    "        \n",
    "        layers = self.layers\n",
    "        layer = len(layers)\n",
    "        \n",
    "        \n",
    "        ## dimension of weights is the dimension of input+1 (add bias) times the dimension of the next layer +1 \n",
    "        ## except the out layer\n",
    "        \n",
    "        if random_start == 0:\n",
    "            weights = {item:np.ones((layers[item][0]+1, layers[item+1][0]+1)) for item in range(1, layer-1)}\n",
    "            weights[layer-1] = np.ones((layers[layer-1][0]+1, 1))\n",
    "            return weights\n",
    "        \n",
    "        np.random.seed(random_start)\n",
    "        weights = {item:np.random.rand(layers[item][0]+1, layers[item+1][0]+1) for item in range(1, layer-1)}\n",
    "        weights[layer-1] = np.random.rand(layers[layer-1][0]+1, 1)\n",
    "        return weights\n",
    "        \n",
    "    def windows(self, batch):\n",
    "        ## random pop batch size of sampling\n",
    "        index = list(range(len(self.x)))\n",
    "        np.random.shuffle(index)\n",
    "\n",
    "        return self.x[index[:batch]], self.y[index[:batch]]\n",
    "    \n",
    "    def forward(self, weights, x = None):\n",
    "        if x is None:\n",
    "            x = self.x\n",
    "            \n",
    "        next_input = [self.addBias(x)]\n",
    "        \n",
    "        for i in range(1, len(weights)+1):\n",
    "            next_input.append(next_input[i-1]@weights[i])\n",
    "        return next_input\n",
    "    \n",
    "\n",
    "    def ward(self, x, weight, error, function):\n",
    "        \n",
    "        ## there is no error for the input layer\n",
    "        if function =='input':\n",
    "            return x.T@error, _\n",
    "        \n",
    "        derivate = self.deactivation(x, function)\n",
    "        return x.T@error, error@weight.T*derivate\n",
    "    \n",
    "    def back(self, next_input, weights, y, learning):\n",
    "        number = len(self.layers)\n",
    "        error ={number:self.decost(next_input[number-1], y)}\n",
    "        \n",
    "        update = []\n",
    "        for layer in range(number-1, 0, -1):\n",
    "            update, error[layer] = self.ward(next_input[layer-1], weights[layer], error[layer+1], self.layers[layer][1])\n",
    "            if np.isnan(update).any():\n",
    "                return weights, 0\n",
    "            weights[layer] -= learning*update\n",
    "            \n",
    "        return weights, np.sum(abs(update))\n",
    "    \n",
    "    def fit(self, threshold = 10e-3, batch = 256, epochs = 10 ,random_start = 0 , learning = []):\n",
    "        \n",
    "        weights = self.make_weights(random_start)\n",
    "        \n",
    "        \n",
    "        if not learning:\n",
    "            learning = 1/np.power(2, len(self.layers)+ self.nodes[1]+self.x.shape[1])\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            ## automatically reduce the learning step\n",
    "            learning = learning /(epoch+1)\n",
    "            \n",
    "            x, y = self.windows(batch)\n",
    "                               \n",
    "            next_input = self.forward(weights, x)\n",
    "            print('epoch {epoch} of {epochs} with mse {mse}'.format(epoch = epoch+1, epochs = epochs, mse = self.mse(next_input[-1], y) ))\n",
    "            weights, update = self.back(next_input, weights, y, learning)\n",
    "            \n",
    "            if update <= threshold: return\n",
    "            \n",
    "            self.weights = weights\n",
    "            \n",
    "    \n",
    "    def predict(self, x):\n",
    "        pred = self.forward(self.weights, x)[-1]\n",
    "        return pred\n",
    "    \n",
    "    def mse(self,pred, true):\n",
    "        error = pred - true\n",
    "        return error.T@error/len(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [10, 'input'], 2: [4, 'sigmod'], 3: [4, 'sigmod'], 4: [1, 'linear']}\n",
      "epoch 1 of 10 with mse [[6394.44779124]]\n",
      "epoch 2 of 10 with mse [[546.26132455]]\n",
      "epoch 3 of 10 with mse [[95.655366]]\n",
      "epoch 4 of 10 with mse [[63.22396424]]\n",
      "epoch 5 of 10 with mse [[53.96255601]]\n",
      "epoch 6 of 10 with mse [[59.48561139]]\n",
      "epoch 7 of 10 with mse [[43.08762748]]\n",
      "epoch 8 of 10 with mse [[46.9129681]]\n",
      "epoch 9 of 10 with mse [[52.32381729]]\n",
      "epoch 10 of 10 with mse [[44.88919778]]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = neural(train_x, train_y)\n",
    "model.dense()\n",
    "model.complie(cost = 'mse', matrix = 'mse')\n",
    "model.fit(random_start = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mse\n",
    "pred = model.predict(test_x)\n",
    "my_mse = np.square(pred - test_y).sum()/len(pred)\n",
    "end = time.time()\n",
    "my_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "start = time.time()\n",
    "y_train = train_y.T\n",
    "regr = MLPRegressor().fit(train_x, train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = regr.predict(test_x)\n",
    "sk_mse = np.square(pred.reshape(-1,1) - test_y).sum()/len(pred)\n",
    "end = time.time()\n",
    "sk_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'MSE')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(['my','sk'],[my_mse, sk_mse],'ro')\n",
    "plt.title('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Time')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(['my','sk'],[my_time, sk_time],'bo')\n",
    "plt.title('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
